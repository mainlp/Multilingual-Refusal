TRANSFORMERS_CACHE=/mounts/Users/student/xinpeng/data/runs_models/huggingface BNB_CUDA_VERSION=122 python3 -m scripts.multi_test --config output/ja_vector_sweep/meta-llama/Meta-Llama-3.1-8B-Instruct/ko/20250519-232436/1/ko.yaml 